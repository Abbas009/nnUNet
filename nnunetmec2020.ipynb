{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnunetmec2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekgupta891/nnUNet/blob/master/nnunetmec2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwMU3rCeoB-j",
        "colab_type": "text"
      },
      "source": [
        "# **nnUNet (the no new unet) :** for medical image segmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUwUYn48C62N",
        "colab_type": "text"
      },
      "source": [
        "## **Introduction**\n",
        "\n",
        "nnU-Net is an open-source tool that can effectively be used out-of-the-box, rendering state of the art segmentation and catalyzing scientific progress as a framework for automated method design. It provides an end-to-end pipline automated pipeline, which can be trained and inferred on any dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC2pvOFvCtjS",
        "colab_type": "text"
      },
      "source": [
        "## **Motivation**\n",
        "nnU-Net has outperformed start-of-the-art architecture in the Medical Decathlon Challenge, using automized pipeline comprising of pre-processing, augmentation and post-processing, over the unet architecture. It has set a new benchmark in the field of medical image segmentation. Whilst, the pipeline itself take of the hyperparameter tuning and requires no change in the network architecture, to achieve start-of-the-art results.\n",
        "\n",
        "## **Problem Statement**\n",
        "nnU-Net though is complete end-to-end solution, but sometimes getting it up running for dataset, which are not in format mentioned [here](https://github.com/prateekgupta891/nnUNet/blob/master/documentation/setting_up_paths.md) , gets difficult to start with. Training the system of a colab notebook is again a challenge, as at require many manual steps. This tutorial will run you through all the necessary steps required to train your first nnunet model, with verification steps to ensure the correctness of the procedure.\n",
        "\n",
        "## **Tutorial Takes Care of following :**\n",
        "\n",
        "1. Introduces to nnUNet framework\n",
        "2. One-stop tutorial to train and test with different datasets \n",
        "3. Colab Notebook Based Tutorial, will work for local machines too.\n",
        "4. Folder creation, command execution from particular folder location is done by the code.\n",
        "5. For SCGM Challenge Dataset, shows how to ingest the dataset to the nnUNet pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIDI-C7sTbRZ",
        "colab_type": "text"
      },
      "source": [
        "## **nnUNet Complete Work Flow**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtzpPnjS7n5",
        "colab_type": "text"
      },
      "source": [
        "![nnUNet Complete WorkFlow](https://raw.githubusercontent.com/prateekgupta891/nnUNet/master/nnunet_complete_workflow.png)\n",
        "\n",
        "\n",
        "nnU-Net pipeline, using the heuristic rule determine the data-dependent hyperparamters, known as the \"data fingerprint\", to ingest the train data. Blueprint Parameters - loss function, optimizer,architecture, with Inferred parameters - image resampling, normalization, batch and patch size, along with the data fingerprint generates a pipeline fingerprints. Pipeline Fingerprints produces network training for 2D,3D and 3D Cascade using the hyperparamters determined so far. Ensemble of the different network configuration(s), along with post-processing  determines the best average Dice coefficient for the training data. The best configuration will then be used to produce the predictions for the test data. Details about individual component is described below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwjffSPGofJb",
        "colab_type": "text"
      },
      "source": [
        "### **1. Dataset Fingerprint** \n",
        "\n",
        "It contains a set of heuristic rules to infere data-dependent hyperparamters of the pipeline. \n",
        "\n",
        "\n",
        "*   Image size (i.e. number of voxels per spatial dimension) before and after cropping image\n",
        "*   Image Spacing (i.e. physical size of the voxels)\n",
        "*   Modalities (from metadata)\n",
        "*   Number of classes for all images and total number of training cases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQcVo2YrZorQ",
        "colab_type": "text"
      },
      "source": [
        "### **2. Blueprint Parameters** \n",
        "\n",
        "**a. Architecture Template** \n",
        "\n",
        "*  nnUNet architecture closely follows the original U-Net and have recently proposed variations such as residual connection, attention mechanisms, squeeze and excitation, or dilated convolutions. \n",
        "\n",
        "*  Prefer large patch size rather than batch size.\n",
        "\n",
        "**b. Training Schedule**\n",
        " \n",
        "*  100 epochs one epoch defined as iteration over 250 minibatches, \n",
        "\n",
        "*  stochastic gradient descent with nestrov momentum,\n",
        "*  loss is combination of cross-entropy and dice loss.\n",
        "*  Oversampling to handle class imbalance\n",
        "*  *Data Augmentation :*   rotation, scaling, guassian noise, guassian blur, brightness, contrast, simulation of low resolution, gamma and resolution.\n",
        "\n",
        "**c. Inference**\n",
        "\n",
        "*  Images are predicted with a sliding window approach, where the window size equals the patch size used during training. Adjacent predictions overlap by half the size of a patch.\n",
        "\n",
        "*  To suppress stitching artifacts andreduce the influence of positions close to the borders, a Gaussian importance weighting is applied,increasing the weight of the center voxels in the softmax aggregation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJLB_aYXphHP",
        "colab_type": "text"
      },
      "source": [
        "### **3. Inferred Parameters**\n",
        "\n",
        "**a. Intensity Normalization :** \n",
        "* Z-scoring for all modalities except CT.\n",
        "* For CT, it follows a global normalization scheme, which uses 0.5 and 99.5 percentiles  of the foreground voxels for clipping.\n",
        "\n",
        "**b. Resampling :** \n",
        "* to cope up with the heterogeneity in medical domain,\n",
        "* resamples all images to same target spacing using either third order spline, linear or nearest neighbor interpolation.\n",
        "\n",
        "**c. Adaptation of network topology, patch size and batch size :** The network topology for all U-Net configurations is chosen on basis of the median image size after resampling as well as the target spacing the images were resampled to.\n",
        "\n",
        "**d. Initialization :** The patch size is initialized as the median image shape after resampling.\n",
        "\n",
        "**e. Architecture Topology:** \n",
        "* The architecture is configured by determining the number of downsampling operations, performed untill feature map is reduced to 4 voxels or feature map space become anisotropic. \n",
        "* High resolution axes are downsampled separately until their resolution is within factor 2 of the lower resolution axis.\n",
        "* Each axis is downsampled individually, untill the feature map constraints are triggered. \n",
        "* The default kernel size for convolutions is 3×3×3 and 3×3 for 3D U-Net and 2D U-Net, respectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q1Jhsqfxo_3",
        "colab_type": "text"
      },
      "source": [
        "### **4. Emperical Parameters**\n",
        "\n",
        "**a. Ensembling and selection of U-Net configuration(s) :** \n",
        "* automatically ensembles based on average foreground Dice coefficient computed via Cross-validation on training data to use for inference \n",
        "* **Configuration model(s):** single models(2D, 3D fullres, 3D lowres or  fullres U-Net of the cascade) or an ensemble of any two of these configurations. \n",
        "* Models are ensembled by averaging softmax probabilities.\n",
        "\n",
        "**b. Postprocessing:** Connected component-based postprocessing is used.\n",
        "All foreground classes are treated as one component, to improve the average foreground Dice coefficient and if it does not reduce the Dice coefficient for any of the classes, then nnU-Net builds on the outcome of this step and decides whether the same procedure should be performed for individual classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoBRVgXJjzn3",
        "colab_type": "text"
      },
      "source": [
        "## **Different U-Net configurations** \n",
        "\n",
        "1.   **2DU-Net**\n",
        "2.   **3D U-Net Full Resolution**\n",
        "3.   **3D U-Net Cascaded :** where the first U-Net operates on downsampled images and the second is trained to refine the segmentation maps created by the former at full resolution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBJV4lJGTEex",
        "colab_type": "text"
      },
      "source": [
        "![U-Net Network Architecure](https://raw.githubusercontent.com/prateekgupta891/nnUNet/master/nnUNet_architecture2.png)\n",
        "**Figure :** for illustratation purposes. network architecture for LITS dataset, from Medical Decathlon taken from Paper 1 mentioned below. Filters and no. of channels will remain same for any dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY2DYdEXbdyu",
        "colab_type": "text"
      },
      "source": [
        "### **Major Sections:** to train a nnUNet model for the Spinal Cord Gray Matter Segmentation Dataset and infer results as well. Same approach can also be applied on other datasets, with  dataset specific modifications.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwAI8FN4Iir",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**bold text**\n",
        "1. [Setup](#setup)    *(always,cpu,gpu)*\n",
        "\n",
        "2. [Cloning the Repo's](#clone) *(one-time,cpu,gpu)*\n",
        "\n",
        "3. [Install and import libraries](#libraries) *(everytime,cpu,gpu)*\n",
        "\n",
        "4. [Dataset Folder Structure](#folder_structure) *(evertyime,cpu,gpu)*\n",
        "\n",
        "5. [Environment Variables](#env_variables) *(everytime,cpu,gpu)*\n",
        "\n",
        "6. [Unzip,Rename Train and Test Set](#dataset_setup) *(once,cpu,gpu)*\n",
        "\n",
        "7. [Dataset verification](#dataset_verify) *(once,optional,cpu,gpu)*\n",
        "\n",
        "8. [Training Code](#train) *(gpu only)*\n",
        "\n",
        "9. [Inference Code](#infer) *(gpu only)*\n",
        "\n",
        "10. [Submission Code for SCGM](#submit) *(optional,cpu,gpu)*\n",
        "\n",
        "\n",
        "**Note:** for training and inference, you have to run through 1,3,4 everytime for colab users, for local machines, installing libraries and setting up environment variables again is not necessary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5rkX_WLVM9D",
        "colab_type": "text"
      },
      "source": [
        "**Papers:**\n",
        "\n",
        "1) nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation [(arxiv)](https://arxiv.org/pdf/1809.10486.pdf)\n",
        "\n",
        "2) Automated Design of Deep Learning Methods for Biomedical Image Segmentation [(arxiv)](https://arxiv.org/pdf/1904.08128.pdf)\n",
        "\n",
        "**Github repository:**\n",
        "\n",
        "1) [Orginal Repository](https://github.com/MIC-DKFZ/nnUNet) - regularly maintained and changed by the authors.\n",
        "\n",
        "2) [Forked Repository](https://github.com/prateekgupta891/nnUNet) - to ensure a version of nnUNet, using which this tutorial works. As orginal repo is constantly updated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP9BHLQ4AGTu",
        "colab_type": "text"
      },
      "source": [
        "(colab users - Preferrably use GPU runtime, but you can change to GPU runtime afterwards, as and when required.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxUpC3-SLqd7",
        "colab_type": "text"
      },
      "source": [
        "##**1. Setup Section**\n",
        "<a id = \"#setup\"></a> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFAMjhgk91jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for colab users only - mounting the drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4fqtH2k-OQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setup a base directory where everything will be installed - repo,dataset, libraries\n",
        "#This .ipynb notebook needs to placed there as well.\n",
        "import os\n",
        "base_dir = '/content/drive/My Drive/Colab Notebooks'\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrJJ3FWT_W7f",
        "colab_type": "text"
      },
      "source": [
        "##**2. Clone the repository**\n",
        "<a id = '#clone'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rt0PmGg_pbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#comment after once installed\n",
        "!git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
        "#git clone https://github.com/prateekgupta891/nnUNet.git #my forked version\n",
        "!git clone https://github.com/NVIDIA/apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSq91BNdPRsH",
        "colab_type": "text"
      },
      "source": [
        "## **3. Install and Import Libraries**\n",
        "<a id = '#libraries'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSNdbg2WDTna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#colab users - everytime\n",
        "#local machines - once\n",
        "respository_dir = os.path.join(base_dir,'nnUNet')\n",
        "os.chdir(respository_dir)\n",
        "\n",
        "!pip install -e .\n",
        "#(optional step)\n",
        "!pip install --upgrade git+https://github.com/nanohanno/hiddenlayer.git@bugfix/get_trace_graph#egg=hiddenlayer\n",
        "\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj2vt5vkRqKv",
        "colab_type": "text"
      },
      "source": [
        "(**Colab Users:** You must restart your runtime after installing the libraries.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDA08Yo3PifU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#libraries\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "import json\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "#for colab users only - keep the base directory same as above\n",
        "import os\n",
        "base_dir = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "repository_dir = os.path.join(base_dir,'nnUNet')\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdJ3WoUxRV4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3574810a-cec6-4f6b-b85e-a6ac568397e5"
      },
      "source": [
        "if os.getcwd()==base_dir:\n",
        "    \n",
        "    print('We are in the correct directory')\n",
        "else:\n",
        "    print(\"Run set base directory step again, then check to verify.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We are in the correct directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFSfF07wXs1i",
        "colab_type": "text"
      },
      "source": [
        "<a id = '#folder_structure'></a>\n",
        "## **4. Dataset Folder Structure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARyAWPHFRbN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_if_dont_exist(folder_path,overwrite=False):\n",
        "    \"\"\"\n",
        "    creates a folder if it doesnot exists\n",
        "    input: \n",
        "    folder_path : relative path of the folder which needs to be created\n",
        "    over_write :(default: False) if True overwrite the existing folder \n",
        "    \"\"\"\n",
        "    if os.path.exists(folder_path):\n",
        "        \n",
        "        if not overwrite:\n",
        "            print(f'{folder_path} exists.')\n",
        "        else:\n",
        "            print(f\"{folder_path} overwritten\")\n",
        "            shutil.rmtree(folder_path)\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "    else:\n",
        "      os.makedirs(folder_path)\n",
        "      print(f\"{folder_path} created!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSX71vh73ugt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "**Custom Task Id starts at 101,** to ensure that there will be no conflicts with downloaded pretrained models.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Task Naming Convention: Task[Task Id]_[Task Name] eg. Task101_SCGM\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib5XdSZIXcj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task_name = 'Task101_SCGM' #change here for different task name\n",
        "nnunet_dir = \"nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data\"\n",
        "task_folder_name = os.path.join(nnunet_dir,task_name)\n",
        "train_image_dir = os.path.join(task_folder_name,'imagesTr')\n",
        "train_label_dir = os.path.join(task_folder_name,'labelsTr')\n",
        "test_dir = os.path.join(task_folder_name,'imagesTs')\n",
        "main_dir = os.path.join(base_dir,'nnUnet/nnunet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pU7_h5JXeTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "make_if_dont_exist(task_folder_name,overwrite = False)\n",
        "make_if_dont_exist(train_image_dir)\n",
        "make_if_dont_exist(train_label_dir)\n",
        "make_if_dont_exist(test_dir,overwrite= False)\n",
        "make_if_dont_exist(os.path.join(main_dir,'nnunet_trained_models'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYO2HVkegkkS",
        "colab_type": "text"
      },
      "source": [
        "## **5.Environment Variables**\n",
        "<a id = '#env_variables'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TDrmYRLgjSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['nnUNet_raw_data_base'] = os.path.join(main_dir,'nnUNet_raw_data_base')\n",
        "os.environ['nnUNet_preprocessed'] = os.path.join(main_dir,'preprocessed')\n",
        "os.environ['RESULTS_FOLDER'] = os.path.join(main_dir,'nnUNet_trained_models')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OSPNZos70Cz",
        "colab_type": "text"
      },
      "source": [
        "**Colab Users:** Everytime you re-run or restart your kernel always run untill this point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CfdGthC4KhY",
        "colab_type": "text"
      },
      "source": [
        "## **6. Unzip,Rename Train and Test Set**\n",
        "<a id = '#dataset_setup'></a>\n",
        "\n",
        "**(Manual Task)** Get the train and test data in zip form and place it \n",
        " in the /nnUNet/nnunet/nnUNet_raw_data_base/nnUNet_raw_data folder.\n",
        "\n",
        "Apply to get Spinal Cord Gray Matter Challenge [Dataset](http://cmictig.cs.ucl.ac.uk/niftyweb/challenge/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzD5Ya6wm5Xn",
        "colab_type": "text"
      },
      "source": [
        "Code will take care of the following:\n",
        "\n",
        "1. Unzip train and test files\n",
        "\n",
        "2. Renaming the train images and labels to match and placing in resp. dirs.\n",
        "\n",
        "3. Putting testing data in the folder, removing text files\n",
        "\n",
        "4. Adding modality at the end of each file, as nnunet can train on multiple modalities together\n",
        "\n",
        "5. Creating dataset.json \n",
        "\n",
        "**Note:** For a new dataset, you may need to do few changes, to train. Also, nnUNet works with .nii.gz files only. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6dqTN19kmET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def copy_and_rename(old_location,old_file_name,new_location,new_filename,delete_original = False):\n",
        "\n",
        "    shutil.copy(os.path.join(old_location,old_file_name),new_location)\n",
        "    os.rename(os.path.join(new_location,old_file_name),os.path.join(new_location,new_filename))\n",
        "    if delete_original:\n",
        "        os.remove(os.path.join(old_location,old_file_name))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jhROK0ym6fO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(task_folder_name)\n",
        "if os.path.isfile('training-data-gm-sc-challenge-ismrm16-v20160302b.zip'):\n",
        "    print(f'Training file for exists')\n",
        "else:\n",
        "    print('Training file for SCGM Challenge is not present in the directory')\n",
        "\n",
        "if os.path.isfile('test-data-gm-sc-challenge-ismrm16-v20160401.zip'):\n",
        "    print('Testing file for SCGM Challenge exists')\n",
        "else:\n",
        "    print('Testing file for SCGM Challenge is not present in the directory')\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O52YOFneGKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzipping in nnUNet_raw folder the training data\n",
        "os.chdir(task_folder_name)\n",
        "!unzip training-data-gm-sc-challenge-ismrm16-v20160302b.zip\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsRlhvtonW4q",
        "colab_type": "text"
      },
      "source": [
        "### Rename and Relocate\n",
        "\n",
        "We have 4 annotation of the same image, by different experts in the SCGM Challenge. *( Image , Ann1 )* and *( Image , Ann2 )* can be considered as a different image and label pair. Hence, 4 copies of training .nii.gz file is created with its mapping to the resp. label name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w89GuKbwnz8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#putting training images into folder\n",
        "\n",
        "mask_count = 4 #change if more mask is available\n",
        "\n",
        "for file in os.listdir(task_folder_name):\n",
        "    \n",
        "    if file.endswith('.nii.gz'):\n",
        "        if file.find('mask')!=-1:\n",
        "            #putting mask\n",
        "            shutil.move(os.path.join(task_folder_name,file),train_label_dir)\n",
        "        else:\n",
        "            #making 4 copies\n",
        "            for mask in range(1,mask_count+1):\n",
        "                new_filename = file[:file.find('-image')] + '-mask-r' + str(mask) + '.nii.gz'\n",
        "                if mask==mask_count:\n",
        "                    copy_and_rename(task_folder_name,file,train_image_dir,new_filename,delete_original = True)\n",
        "                else:\n",
        "                    copy_and_rename(task_folder_name,file,train_image_dir,new_filename)\n",
        "    #removing all other files installed due to the unzip\n",
        "    elif file.endswith('.txt'):\n",
        "        os.remove(os.path.join(task_folder_name,file))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGR5w7n4oFCk",
        "colab_type": "text"
      },
      "source": [
        "Verification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B27xTmMcn1ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = os.listdir(train_image_dir)\n",
        "label_files = os.listdir(train_label_dir)\n",
        "print(\"train image files:\",len(train_files))\n",
        "print(\"train label files:\",len(label_files))\n",
        "print(\"Matches:\",len(set(train_files).intersection(set(label_files))))\n",
        "\n",
        "#should be equal to 160 for SCGM Challenge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYuUAfjHoDgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzip the testing files in nnUNet_raw folder\n",
        "os.chdir(task_folder_name)\n",
        "!unzip test-data-gm-sc-challenge-ismrm16-v20160401.zip\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjHDon9Vn2_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in os.listdir(task_folder_name):\n",
        "\n",
        "    if file.endswith('.nii.gz'):\n",
        "        #putting mask\n",
        "        shutil.move(os.path.join(task_folder_name,file),test_dir)\n",
        "    \n",
        "    #removing all other files installed due to the unzip\n",
        "    elif file.endswith('.txt'):\n",
        "        os.remove(os.path.join(task_folder_name,file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn46w0FTn5-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Testing files:\",len(os.listdir(test_dir)))\n",
        "print(test_dir)\n",
        "#for spinal cord dataset testing files needs to be equal to 40."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QUfzfcIqndD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#renaming to add the modality for SCGM there is only one modality \n",
        "#images should be added with 0000\n",
        "#can be skipped if modality is already mentioned\n",
        "#re-write for multiple modalities\n",
        "\n",
        "def check_modality(filename):\n",
        "    \"\"\"\n",
        "    check for the existence of modality\n",
        "    return False if modality is not found else True\n",
        "    \"\"\"\n",
        "    end = filename.find('.nii.gz')\n",
        "    modality = filename[end-4:end]\n",
        "    for mod in modality: \n",
        "        if not(ord(mod)>=48 and ord(mod)<=57): #if not in 0 to 9 digits\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def rename_for_single_modality(directory):\n",
        "    \n",
        "    for file in os.listdir(directory):\n",
        "        \n",
        "        if check_modality(file)==False:\n",
        "            new_name = file[:file.find('.nii.gz')]+\"_0000.nii.gz\"\n",
        "            os.rename(os.path.join(directory,file),os.path.join(directory,new_name))\n",
        "            print(f\"Renamed to {new_name}\")\n",
        "        else:\n",
        "            print(f\"Modality present: {file}\")\n",
        "\n",
        "rename_for_single_modality(train_image_dir)\n",
        "rename_for_single_modality(test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-XfPdmpq79m",
        "colab_type": "text"
      },
      "source": [
        "### Creating **dataset.json**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmrSXf2srHjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
        "json_file_exist = False\n",
        "\n",
        "if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
        "    print('dataset.json already exist!')\n",
        "    json_file_exist = True\n",
        "\n",
        "if json_file_exist==False or overwrite_json_file:\n",
        "\n",
        "    json_dict = OrderedDict()\n",
        "    json_dict['name'] = task_name\n",
        "    json_dict['description'] = \"Spinal Cord Gray Matter Segmenation Challenge\"\n",
        "    json_dict['tensorImageSize'] = \"3D\"\n",
        "    json_dict['reference'] = \"see challenge website\"\n",
        "    json_dict['licence'] = \"see challenge website\"\n",
        "    json_dict['release'] = \"0.0\"\n",
        "\n",
        "    #you may mention more than one modality\n",
        "    json_dict['modality'] = {\n",
        "        \"0\": \"MRI\"\n",
        "    }\n",
        "    #labels+1 should be mentioned for all the labels in the dataset\n",
        "    json_dict['labels'] = {\n",
        "        \"0\": \"background\",\n",
        "        \"1\": \"gray matter\",\n",
        "        \"2\": \"white matter\"\n",
        "    }\n",
        "    \n",
        "    train_ids = os.listdir(train_label_dir)\n",
        "    test_ids = os.listdir(test_dir)\n",
        "    json_dict['numTraining'] = len(train_ids)\n",
        "    json_dict['numTest'] = len(test_ids)\n",
        "\n",
        "    #no modality in train image and labels in dataset.json \n",
        "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
        "\n",
        "    #removing the modality from test image name to be saved in dataset.json\n",
        "    json_dict['test'] = [\"./imagesTs/%s\" % (i[:i.find(\"_0000\")]+'.nii.gz') for i in test_ids]\n",
        "\n",
        "    with open(os.path.join(task_folder_name,\"dataset.json\"), 'w') as f:\n",
        "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
        "\n",
        "    if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
        "        if json_file_exist==False:\n",
        "            print('dataset.json created!')\n",
        "        else: \n",
        "            print('dataset.json overwritten!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMPYPrUVslFi",
        "colab_type": "text"
      },
      "source": [
        "##**7. Dataset Verification**\n",
        "<a id = '#dataset_verify'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjGLZk148MRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#running it from the experiment_planning folder to verify the path settings\n",
        "os.chdir(main_dir)\n",
        "!python experiment_planning/nnUNet_plan_and_preprocess.py -t 101 --verify_dataset_integrity\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYdrPRfqVHl7",
        "colab_type": "text"
      },
      "source": [
        "## **8. Training Code**\n",
        "<a id = '#train'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfapEc3NOmQb",
        "colab_type": "text"
      },
      "source": [
        "nnU-Net stores a checkpoint every 50 epochs. If you need to continue a previous training, just add a -c to the training command.\n",
        "\n",
        "**Generic Training Commands:**\n",
        "\n",
        "    nnUNet_train CONFIGURATION TRAINER_CLASS_NAME TASK_NAME_OR_ID FOLD (additional options)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKAjmGzHvxUW",
        "colab_type": "text"
      },
      "source": [
        "**For 2D:**   ``` nnUNet_train 2d nnUNetTrainerV2 TaskXXX_MYTASK FOLD```\n",
        "\n",
        "**For 3D Full resolution:** ```    nnUNet_train 3d_fullres nnUNetTrainerV2 TaskXXX_MYTASK FOLD```\n",
        "\n",
        "**For Cascaded 3D:** \n",
        "\n",
        "First Run lowres: ```   nnUNet_train 3d_lowres nnUNetTrainerV2 TaskXXX_MYTASK FOLD``` \n",
        "\n",
        "Then Run fullres: ``` nnUNet_train 3d_cascade_fullres nnUNetTrainerV2CascadeFullRes TaskXXX_MYTASK FOLD ```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OiB3r5sNguW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#colab users - mandatory\n",
        "#local machine - once is sufficient\n",
        "os.chdir('apex')\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC614zRCRguc",
        "colab_type": "text"
      },
      "source": [
        "Training for 3D fullres with Trainer V2 and for Fold 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It1UZ04bQ62r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(main_dir)\n",
        "!nnUNet_train 3d_fullres nnUNetTrainerV2 101 0 -c\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jvxL2xHQ4sm",
        "colab_type": "text"
      },
      "source": [
        "##**9. Inference Code**\n",
        "<a id = '#infer'></a>\n",
        "```nnUNet_find_best_configuration``` will print inference commands you need to use. The easiest way to run inference is to simply use these commands.\n",
        "\n",
        "\n",
        "For each of the desired configurations, run:\n",
        "```\n",
        "nnUNet_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -t TASK_NAME_OR_ID -m CONFIGURATION --save_npz\n",
        "```\n",
        "Only specify --save_npz if you intend to use ensembling. --save_npz will make the command save the softmax probabilities alongside of the predicted segmentation masks requiring a lot of disk space.\n",
        "\n",
        "**Note:** Please select a separate OUTPUT_FOLDER for each configuration!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSfJ8sQE3C37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#optional\n",
        "os.chdir(repository_dir)\n",
        "!nnUNet_find_best_configuration -t 101\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bLhYZT8Poxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_dir = os.path.join(main_dir,'nnUNet_Prediction_Results',task_name)\n",
        "make_if_dont_exist(result_dir)\n",
        "\n",
        "team_name = 'prateek3' #make sure to change for your own team name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jaO3vKWQg0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#location where you want save your results, will be created if dont exist\n",
        "os.chdir(main_dir)\n",
        "!nnUNet_predict -i nnUNet_raw_data_base/nnUNet_raw_data/Task101_SCGM/imagesTs -o nnUNet_Prediction_Results/Task101_SCGM -t 101 -tr nnUNetTrainerV2 -m 3d_fullres --num_threads_preprocessing 1\n",
        "os.chdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1klVm1u3zm0",
        "colab_type": "text"
      },
      "source": [
        "If you wish to run ensembling, you can ensemble the predictions from several configurations with the following command:\n",
        "```\n",
        "nnUNet_ensemble -f FOLDER1 FOLDER2 ... -o OUTPUT_FOLDER -pp POSTPROCESSING_FILE\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_J4AHCePDLT",
        "colab_type": "text"
      },
      "source": [
        "## **10. SCGM submission** (optional)\n",
        "<a id = 'submit'></a>\n",
        "\n",
        "While trianing, we trained the dataset to learn, **White Matter** as well as **Gray Matter**. But for the challenge we only need to predict *Gray matter* labelled as *1*, and *everything else is 0*. So we convert the labels.\n",
        "\n",
        "Test images naming convention: **[Original test filename]-[team name].nii.gz**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LgCThfxQk94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#specific to the submission\n",
        "\n",
        "submission_folder = os.path.join(result_dir,'submission_folder')\n",
        "make_if_dont_exist(submission_folder)\n",
        "\n",
        "for file in os.listdir(submission_dir):\n",
        "    \n",
        "    if file.endswith('.nii.gz'):\n",
        "        \n",
        "        img = nib.load(os.path.join(result_dir,file))\n",
        "\n",
        "        img_np = np.array(img.dataobj)\n",
        "        img_np[img_np==2.0] = 0.0\n",
        "        img_nifti = nib.Nifti1Image(img_np,affine = np.eye(4))\n",
        "\n",
        "        new_file = file[:file.find('image')]+team_name+'.nii.gz'\n",
        "        \n",
        "        nib.save(img_nifti, os.path.join(submission_folder,new_file))\n",
        "\n",
        "        print(new_file)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyKI8_5TPd5_",
        "colab_type": "text"
      },
      "source": [
        "**Test Results:**\n",
        "Download the the folder, and upload with at the following [link](http://niftyweb.cs.ucl.ac.uk/program.php?p=CHALLENGE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnbYaA5_m2IU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "![picture](https://raw.githubusercontent.com/prateekgupta891/nnUNet/master/result.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpb75yADwc4B",
        "colab_type": "text"
      },
      "source": [
        "**Note:** These results are achieved with only 10 epochs on 3D full resolution on a single fold without post-processing, and it is better than results, mentioned by SCGM Challenge website [here](http://niftyweb.cs.ucl.ac.uk/program.php?p=CHALLENGE).\n",
        "Dice Score is better by 0.04 from the best results."
      ]
    }
  ]
}